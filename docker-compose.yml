version: '3.8'

services:
  # gateway:
  #   build:
  #     context: .
  #     dockerfile: docker/gateway/Dockerfile
  #   ports:
  #     - "18765:8000"
  #   environment:
  #     - BOT_MANAGER_URL=http://bot-manager:8080
  #     - TRANSCRIPTION_URL=http://whisperlive-trt:9090
  #   volumes:
  #     - ./src/gateway:/app
  #   command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
  #   depends_on:
  #     - bot-manager
  #     - whisperlive-trt

  bot-manager:
    build:
      context: .
      dockerfile: docker/bot-manager/Dockerfile
    ports:
      - ":8080"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - BOT_IMAGE=vexa-bot:latest
      - DOCKER_NETWORK=vexa_default
      - LOG_LEVEL=DEBUG
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=vexa
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - ADMIN_API_TOKEN=supersecretadmintoken
      - DOCKER_HOST=unix://var/run/docker.sock
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./src/bot-manager:/app/bot-manager
    working_dir: /app
    command: uvicorn bot-manager.main:app --host 0.0.0.0 --port 8080
    depends_on:
      - redis
      - postgres

  whisperlive-trt:
    build:
      context: .
      dockerfile: docker/whisperlive-trt/Dockerfile
    volumes:
      - whisper-model-data:/app/TensorRT-LLM-examples/whisper
      - ./WhisperLive/whisper_live:/app/whisper_live
    environment:
      - TRANSCRIPTION_COLLECTOR_URL=ws://transcription-collector:8000/collector
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - transcription-collector

  transcription-collector:
    build:
      context: .
      dockerfile: docker/transcription-collector/Dockerfile
    ports:
      - ":8000"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=vexa
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
      - postgres

  # bot:
  #   build:
  #     context: ./vexa-bot-submodule/core
  #     dockerfile: Dockerfile
  #   image: bot:latest
  #   environment:
  #     BOT_CONFIG: |
  #       {"platform": "google", "meetingUrl": "https://meet.google.com/xxx-xxxx-xxx", "botName": "DevBot", "token": "123", "connectionId": "", "automaticLeave": {"waitingRoomTimeout": 300000, "noOneJoinedTimeout": 300000, "everyoneLeftTimeout": 300000}}
  #     TRANSCRIPTION_SERVICE: http://whisperlive-trt:9090
  #   volumes:
  #     - ./vexa-bot-submodule:/app/vexa-bot
  #     - ./src/bot/transcript-adapter.js:/app/adapter.js
  #   deploy:
  #     replicas: 1

  redis:
    image: redis:7.0-alpine
    volumes:
      - redis-data:/data

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=vexa
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres-data:/var/lib/postgresql/data

  # celery-worker:
  #   build:
  #     context: .
  #     dockerfile: docker/bot-manager/Dockerfile
  #   environment:
  #     - ENVIRONMENT=local
  #     - BOT_IMAGE=bot:latest
  #     - TRANSCRIPTION_SERVICE=http://whisperlive-trt:9090
  #     - REDIS_URL=redis://redis:6379/0
  #     - DB_HOST=postgres
  #     - DB_PORT=5432
  #     - DB_NAME=vexa
  #     - DB_USER=postgres
  #     - DB_PASSWORD=postgres
  #   volumes:
  #     - ./src/bot-manager:/app
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   command: celery -A app.tasks.monitoring worker --loglevel=info
  #   depends_on:
  #     - redis
  #     - postgres

volumes:
  redis-data:
  postgres-data:
  whisper-model-data: 