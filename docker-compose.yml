version: '3.8'

services:
  # gateway:
  #   build:
  #     context: .
  #     dockerfile: docker/gateway/Dockerfile
  #   ports:
  #     - "18765:8000"
  #   environment:
  #     - BOT_MANAGER_URL=http://bot-manager:8080
  #     - TRANSCRIPTION_URL=http://whisperlive-trt:9090
  #   volumes:
  #     - ./src/gateway:/app
  #   command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
  #   depends_on:
  #     - bot-manager
  #     - whisperlive-trt

  # bot-manager:
  #   build:
  #     context: .
  #     dockerfile: docker/bot-manager/Dockerfile
  #   ports:
  #     - "8081:8080"
  #   environment:
  #     - ENVIRONMENT=local
  #     - BOT_IMAGE=bot:latest
  #     - TRANSCRIPTION_SERVICE=http://whisperlive-trt:9090
  #     - REDIS_URL=redis://redis:6379/0
  #     - DB_HOST=postgres
  #     - DB_PORT=5432
  #     - DB_NAME=vexa
  #     - DB_USER=postgres
  #     - DB_PASSWORD=postgres
  #   volumes:
  #     - ./src/bot-manager:/app
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   command: uvicorn main:app --host 0.0.0.0 --port 8080 --reload
  #   depends_on:
  #     - redis
  #     - postgres

  whisperlive-trt:
    build:
      context: .
      dockerfile: docker/whisperlive-trt/Dockerfile
    ports:
      - "9090:9090"
    volumes:
      - whisper-model-data:/app/TensorRT-LLM-examples/whisper
      - ./WhisperLive/whisper_live:/app/whisper_live
    environment:
      - TRANSCRIPTION_COLLECTOR_URL=ws://transcription-collector:8000/collector
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - transcription-collector

  transcription-collector:
    build:
      context: .
      dockerfile: docker/transcription-collector/Dockerfile
    # No port exposure - only internal service
    ports:
      - "9758:8000"  # Expose on port 8001
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=vexa
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
      - postgres

  # bot:
  #   build:
  #     context: ./vexa-bot-submodule/core
  #     dockerfile: Dockerfile
  #   image: bot:latest
  #   environment:
  #     BOT_CONFIG: |
  #       {"platform": "google", "meetingUrl": "https://meet.google.com/xxx-xxxx-xxx", "botName": "DevBot", "token": "123", "connectionId": "", "automaticLeave": {"waitingRoomTimeout": 300000, "noOneJoinedTimeout": 300000, "everyoneLeftTimeout": 300000}}
  #     TRANSCRIPTION_SERVICE: http://whisperlive-trt:9090
  #   volumes:
  #     - ./vexa-bot-submodule:/app/vexa-bot
  #     - ./src/bot/transcript-adapter.js:/app/adapter.js
  #   deploy:
  #     replicas: 1

  redis:
    image: redis:7.0-alpine
    volumes:
      - redis-data:/data

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=vexa
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres-data:/var/lib/postgresql/data

  # celery-worker:
  #   build:
  #     context: .
  #     dockerfile: docker/bot-manager/Dockerfile
  #   environment:
  #     - ENVIRONMENT=local
  #     - BOT_IMAGE=bot:latest
  #     - TRANSCRIPTION_SERVICE=http://whisperlive-trt:9090
  #     - REDIS_URL=redis://redis:6379/0
  #     - DB_HOST=postgres
  #     - DB_PORT=5432
  #     - DB_NAME=vexa
  #     - DB_USER=postgres
  #     - DB_PASSWORD=postgres
  #   volumes:
  #     - ./src/bot-manager:/app
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   command: celery -A app.tasks.monitoring worker --loglevel=info
  #   depends_on:
  #     - redis
  #     - postgres


volumes:
  redis-data:
  postgres-data:
  whisper-model-data: 