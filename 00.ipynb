{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from vexa_client import VexaClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_client = VexaClient(\n",
    "    base_url=\"http://localhost:8056\",\n",
    "    admin_key=\"superwsercetkeyesuperxample\"  # From docker-compose.yml\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Making POST request to http://localhost:8056/admin/users\n",
      "DEBUG: Headers: {'Content-Type': 'application/json', 'X-Admin-API-Key': 'superwsercetkeyesuperxample'}\n",
      "DEBUG: Params: None\n",
      "DEBUG: JSON data: {'email': '402818@example.com', 'name': 'Ilia Semukhin'}\n",
      "DEBUG: Response status: 201\n",
      "DEBUG: Response headers: {'date': 'Tue, 08 Apr 2025 17:38:29 GMT, Tue, 08 Apr 2025 17:38:30 GMT', 'server': 'uvicorn, uvicorn', 'content-length': '120', 'content-type': 'application/json'}\n",
      "DEBUG: Response content: {\"email\":\"402818@example.com\",\"name\":\"Ilia Semukhin\",\"image_url\":null,\"id\":32,\"created_at\":\"2025-04-08T17:38:30.412413\"}...\n"
     ]
    }
   ],
   "source": [
    "new_user = admin_client.create_user(email=f\"{random.randint(1, 1000000)}@example.com\", name=\"Ilia Semukhin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_id = new_user['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Making POST request to http://localhost:8056/admin/users/32/tokens\n",
      "DEBUG: Headers: {'Content-Type': 'application/json', 'X-Admin-API-Key': 'superwsercetkeyesuperxample'}\n",
      "DEBUG: Params: None\n",
      "DEBUG: JSON data: None\n",
      "DEBUG: Response status: 201\n",
      "DEBUG: Response headers: {'date': 'Tue, 08 Apr 2025 17:38:30 GMT, Tue, 08 Apr 2025 17:38:30 GMT', 'server': 'uvicorn, uvicorn', 'content-length': '115', 'content-type': 'application/json'}\n",
      "DEBUG: Response content: {\"user_id\":32,\"id\":65,\"token\":\"4l3OzYPG2Xw2FvlSG5ClcfoFpEfFeAa1SRLvCzXB\",\"created_at\":\"2025-04-08T17:38:31.232404\"}...\n"
     ]
    }
   ],
   "source": [
    "token_info = admin_client.create_token(user_id=user_id)\n",
    "user_api_key = token_info['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4l3OzYPG2Xw2FvlSG5ClcfoFpEfFeAa1SRLvCzXB'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = VexaClient(\n",
    "    base_url=\"http://localhost:8056\",\n",
    "    api_key=user_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_url=\"https://meet.google.com/gcc-nydg-fge\"\n",
    "native_meeting_id = meeting_url.split(\"/\")[-1]  # \"xyz-abcd-123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Making POST request to http://localhost:8056/bots\n",
      "DEBUG: Headers: {'Content-Type': 'application/json', 'X-API-Key': '4l3OzYPG2Xw2FvlSG5ClcfoFpEfFeAa1SRLvCzXB'}\n",
      "DEBUG: Params: None\n",
      "DEBUG: JSON data: {'platform': 'google_meet', 'native_meeting_id': 'gcc-nydg-fge', 'bot_name': 'MyBot'}\n",
      "DEBUG: Response status: 201\n",
      "DEBUG: Response headers: {'date': 'Tue, 08 Apr 2025 17:40:33 GMT, Tue, 08 Apr 2025 17:40:34 GMT', 'server': 'uvicorn, uvicorn', 'content-length': '393', 'content-type': 'application/json'}\n",
      "DEBUG: Response content: {\"id\":46,\"user_id\":32,\"platform\":\"google_meet\",\"native_meeting_id\":\"gcc-nydg-fge\",\"constructed_meeting_url\":\"https://meet.google.com/gcc-nydg-fge\",\"status\":\"active\",\"bot_container_id\":\"bb4b267f22b68e80db542fc1da7ab1e04f94e1483f7745f9a83cb991a4499750\",\"start_time\":\"2025-04-08T17:40:37.998578\",\"end_time\":null,\"created_at\":\"2025-04-08T17:40:34.697913\",\"updated_at\":\"2025-04-08T17:40:34.704495\"}...\n"
     ]
    }
   ],
   "source": [
    "meeting_info = client.request_bot(\n",
    "    platform=\"google_meet\",\n",
    "    native_meeting_id=native_meeting_id,\n",
    "    bot_name=\"MyBot\"\n",
    ")\n",
    "meeting_id = meeting_info['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Making GET request to http://localhost:8056/meetings\n",
      "DEBUG: Headers: {'Content-Type': 'application/json', 'X-API-Key': '4l3OzYPG2Xw2FvlSG5ClcfoFpEfFeAa1SRLvCzXB'}\n",
      "DEBUG: Params: None\n",
      "DEBUG: JSON data: None\n",
      "DEBUG: Response status: 200\n",
      "DEBUG: Response headers: {'date': 'Tue, 08 Apr 2025 17:42:07 GMT, Tue, 08 Apr 2025 17:42:06 GMT', 'server': 'uvicorn, uvicorn', 'content-length': '408', 'content-type': 'application/json'}\n",
      "DEBUG: Response content: {\"meetings\":[{\"id\":46,\"user_id\":32,\"platform\":\"google_meet\",\"native_meeting_id\":\"gcc-nydg-fge\",\"constructed_meeting_url\":\"https://meet.google.com/gcc-nydg-fge\",\"status\":\"active\",\"bot_container_id\":\"bb4b267f22b68e80db542fc1da7ab1e04f94e1483f7745f9a83cb991a4499750\",\"start_time\":\"2025-04-08T17:40:37.998578\",\"end_time\":null,\"created_at\":\"2025-04-08T17:40:34.697913\",\"updated_at\":\"2025-04-08T17:40:34.704495\"}]}...\n"
     ]
    }
   ],
   "source": [
    "meetings = client.get_meetings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Making GET request to http://localhost:8056/transcripts/google_meet/gcc-nydg-fge\n",
      "DEBUG: Headers: {'Content-Type': 'application/json', 'X-API-Key': '4l3OzYPG2Xw2FvlSG5ClcfoFpEfFeAa1SRLvCzXB'}\n",
      "DEBUG: Params: None\n",
      "DEBUG: JSON data: None\n",
      "DEBUG: Response status: 200\n",
      "DEBUG: Response headers: {'date': 'Tue, 08 Apr 2025 18:13:21 GMT, Tue, 08 Apr 2025 18:13:21 GMT', 'server': 'uvicorn, uvicorn', 'content-length': '592274', 'content-type': 'application/json'}\n",
      "DEBUG: Response content: {\"id\":46,\"platform\":\"google_meet\",\"native_meeting_id\":\"gcc-nydg-fge\",\"constructed_meeting_url\":\"https://meet.google.com/gcc-nydg-fge\",\"status\":\"active\",\"start_time\":\"2025-04-08T17:40:37.998578\",\"end_time\":null,\"segments\":[{\"start\":0.0,\"end\":2.56,\"text\":\" to get real-time transcripts.\",\"language\":null,\"created_at\":\"2025-04-08T17:40:59.641414\",\"speaker\":null},{\"start\":0.0,\"end\":3.68,\"text\":\" to get real-time transcripts from\",\"language\":null,\"created_at\":\"2025-04-08T17:41:00.623975\",\"speaker\":null...\n"
     ]
    }
   ],
   "source": [
    "transcript = client.get_transcript(native_meeting_id=native_meeting_id,platform='google_meet')\n",
    "segments = transcript.get('segments', [])\n",
    "df = pd.DataFrame(transcript['segments']).sort_values(['created_at','start']).drop_duplicates('start',keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>created_at</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.430</td>\n",
       "      <td>30.500</td>\n",
       "      <td>Yeah, so tell me about about yourself. What's...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T17:41:27.969143</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>37.469</td>\n",
       "      <td>38.109</td>\n",
       "      <td>Is it about...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T17:41:35.600229</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>146.121</td>\n",
       "      <td>161.045</td>\n",
       "      <td>Yeah</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T17:43:39.192758</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>160.130</td>\n",
       "      <td>162.130</td>\n",
       "      <td>There's a bit of a risk.</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T17:43:45.402629</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>162.130</td>\n",
       "      <td>166.430</td>\n",
       "      <td>Okay?</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T17:43:45.402979</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>520.533</td>\n",
       "      <td>522.533</td>\n",
       "      <td>great</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T18:09:48.451215</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>520.193</td>\n",
       "      <td>522.533</td>\n",
       "      <td>great</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T18:09:48.838952</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>523.536</td>\n",
       "      <td>527.696</td>\n",
       "      <td>Thank you for listening, it was really, reall...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T18:09:53.581741</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>529.956</td>\n",
       "      <td>531.956</td>\n",
       "      <td>Thank you. Good night.</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T18:09:57.961503</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>527.696</td>\n",
       "      <td>531.956</td>\n",
       "      <td>Thank you. Good night.</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-08T18:09:59.022411</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        start      end                                               text  \\\n",
       "72      6.430   30.500   Yeah, so tell me about about yourself. What's...   \n",
       "138    37.469   38.109                                     Is it about...   \n",
       "263   146.121  161.045                                               Yeah   \n",
       "277   160.130  162.130                           There's a bit of a risk.   \n",
       "318   162.130  166.430                                              Okay?   \n",
       "...       ...      ...                                                ...   \n",
       "3161  520.533  522.533                                              great   \n",
       "3153  520.193  522.533                                              great   \n",
       "3164  523.536  527.696   Thank you for listening, it was really, reall...   \n",
       "3237  529.956  531.956                             Thank you. Good night.   \n",
       "3228  527.696  531.956                             Thank you. Good night.   \n",
       "\n",
       "     language                  created_at speaker  \n",
       "72       None  2025-04-08T17:41:27.969143    None  \n",
       "138      None  2025-04-08T17:41:35.600229    None  \n",
       "263      None  2025-04-08T17:43:39.192758    None  \n",
       "277      None  2025-04-08T17:43:45.402629    None  \n",
       "318      None  2025-04-08T17:43:45.402979    None  \n",
       "...       ...                         ...     ...  \n",
       "3161     None  2025-04-08T18:09:48.451215    None  \n",
       "3153     None  2025-04-08T18:09:48.838952    None  \n",
       "3164     None  2025-04-08T18:09:53.581741    None  \n",
       "3237     None  2025-04-08T18:09:57.961503    None  \n",
       "3228     None  2025-04-08T18:09:59.022411    None  \n",
       "\n",
       "[181 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Yeah, so tell me about about yourself. What's that that you're doing?\",\n",
       " ' Is it about...',\n",
       " ' Yeah',\n",
       " \" There's a bit of a risk.\",\n",
       " ' Okay?',\n",
       " \" Yeah, I've been switching another, the proprietary version now, the other, the other.\",\n",
       " ' the other',\n",
       " ' Thank you very much.',\n",
       " \" You're most welcome.\",\n",
       " \" I'm just curious what types of model I've been using for that, I suppose it's all because\",\n",
       " \" I suppose it's a little bit...\",\n",
       " \" about yourself? What's that you're doing? Are you about, you said you're about machine learning?\",\n",
       " \" I suppose it's a lot of kind of boosting trees, yes, this is like a pretty large language\",\n",
       " ' Is it about STG and TGS things, have you played around this stuff?',\n",
       " ' model. Yeah, so mostly table type of table data, right?',\n",
       " ' So mostly table type of table data, right?',\n",
       " ' See, okay.',\n",
       " ' Thank you very much.',\n",
       " ' Yes, yes.',\n",
       " ' Yeah.',\n",
       " ' Thanks.',\n",
       " ' Thank you.',\n",
       " \" Yeah, I've been switching another the proprietary policy now the other\",\n",
       " \" Okay. Okay. So the thing which I'm doing is done all in-premises. I mean, I mean, it's deployed.\",\n",
       " ' So, no way.',\n",
       " ' it. So no API is used for transcription. So yeah, I have a development server, which',\n",
       " \" which is now it's run on my own GPUs.\",\n",
       " ' And, yeah, and now the backend for transcription is something which is called Life Whisperer,',\n",
       " \" or whisper life maybe whisper life but it's I forked it and modified in order to like to\",\n",
       " ' to get a stream and forward and stream further the transcription which is then de-deblocated',\n",
       " ' and stored in the database. And there is a bot service which is deploying bots which you can',\n",
       " ' you can request with the API and just get the transcription back from another API endpoint.',\n",
       " \" So that's basically it and yeah and obviously there is a lot of things to do there.\",\n",
       " \" I'm pretty sure you are a Python developer, right?\",\n",
       " ' Yeah.',\n",
       " ' developer, right?',\n",
       " ' Yeah.',\n",
       " ' Yeah',\n",
       " ' Yes',\n",
       " \" Yeah, I'm pretty sure.\",\n",
       " ' OK.',\n",
       " \" And tell me what's your...\",\n",
       " \" where are you going, why are you actually stopped for looking at Vaxxay and approach me, what's your\",\n",
       " \" What's your motivation?\",\n",
       " ' Yeah, okay, good, good questions.',\n",
       " ' Um, so.',\n",
       " ' I started to work so like about a year and a half ago.',\n",
       " ' I started to work so like about a year and a half ago.',\n",
       " \" So I'll make it a little bit further.\",\n",
       " ' as a meeting note taker.',\n",
       " ' And this time, I doubt if this kind of business model even exists.',\n",
       " ' exists, like we had a very few examples.',\n",
       " \" And so we actually will build a product and it's running and if you go to there.\",\n",
       " \" Actually, we'll build a product, and it's running.\",\n",
       " \" And if you go to VEX AI, you'll be able to use the proprietary product for free,\",\n",
       " \" As it's a real-time meeting from transcription and it also prettifies the things for you, makes it interactive.\",\n",
       " ' makes it interactive and you will be able to interact with the meeting on the call with the alarm.',\n",
       " ' with the alarm but',\n",
       " ' with the alarm but then the paradigm shift towards the fact is that my',\n",
       " \" understanding of where we are heading is that we'll be mostly interacting with a single interface\",\n",
       " ' which will',\n",
       " ' which will have an agent or a multitude or a variety of agents running there at the same time.',\n",
       " ' time and those agents will be using MCP tools to do stuff for us. So the kind of',\n",
       " ' thing, which is a user interface, which is a service user',\n",
       " ' interface',\n",
       " ' This, this type of thing will go away, will start having the amount of interfaces similar',\n",
       " ' the amount of users and the services will have no interface.',\n",
       " ' So, in that paradigm, you can basically forget and fall away and forget everything about',\n",
       " ' user experience and a front-end building which is kind of a big relief, a big relief.',\n",
       " ' Another thing is that open source, why is it open source?',\n",
       " \" Just one simple idea is that the value of code is getting lower and lower, it's inflation of the value.\",\n",
       " \" It's the inflation of the value of the code.\",\n",
       " ' So, but engagement and community is something that is really valuable.',\n",
       " ' it brings a lot of value.',\n",
       " ' And just because of that, I researched a few commercial open source companies, their business',\n",
       " ' model. I approached the founders, spoke to founders and they basically convinced me of going this way and just...',\n",
       " ' going this way and just release it under MIT or Apache 2 license, which I finally did.',\n",
       " \" And it's a pretty early stage for this open source product, but actually the thing is\",\n",
       " ' that there is a lot of demand for for transcription and for a simple easy-to-use API, which like',\n",
       " ' who any kind of guy who is willing to use Cursor will be able to you know',\n",
       " ' yeah to implement in their own project and',\n",
       " \" know, yeah, to implement in their own project, and the company's central crisis to be able\",\n",
       " ' to run at it.',\n",
       " ' Yeah, actually, my next plan as I basically did, basically I have the pipeline working',\n",
       " \" now. I send the board and they see transcripts coming. And I'm not particularly happy about this.\",\n",
       " ' strong scripts but I just need to play around with the with the model and with the parameters basically',\n",
       " ' for now.',\n",
       " ' for now.',\n",
       " ' for now.',\n",
       " \" I'll just go and start building community around this thing now, just this thing is working.\",\n",
       " ' I have a simple website where you can get an API token and get to start using this thing',\n",
       " ' or you can go to GitHub and deploy this thing yourself, as you wish, as a lot of commercial',\n",
       " ' open source companies are doing.',\n",
       " ' So, everything is about engaging super users like you, not just users, yes, yes, exactly.',\n",
       " ' So because if you are doing like a kind of B2B, B2C normal proprietary product, you get',\n",
       " \" users whose behavior is whether they buy or don't buy,\",\n",
       " \" user don't use they can then can't give you more but and you stay alone or with\",\n",
       " ' those people you pay hard car hard cash and',\n",
       " ' And...',\n",
       " ' And, yeah, engage on super users who are engaged, who at least',\n",
       " ' who at least will give you',\n",
       " ' who at least will give you really meaningful, post meaningful issues on',\n",
       " \" you'd have. It's something that makes a lot of sense.\",\n",
       " ' Yeah, I was thinking about this too.',\n",
       " ' I was thinking, if you basically start getting in a possession,',\n",
       " ' one you basically can create anything from scratch in a few, just in a few days, would',\n",
       " \" you actually want to contribute to open source, but you actually do want because why bother, you'll, you'll still\",\n",
       " \" you'll still, you'll\",\n",
       " \" you'll still, you'll still get crap.\",\n",
       " ' You will have something that looks like helpful and it will not never be state-of-the-art',\n",
       " ' And the state-of-the-art is is where you got',\n",
       " ' And the state of the art is where you get layers and layers of intelligence, of engineers.',\n",
       " ' and augmented intelligence with cursor and best models.',\n",
       " ' And best...',\n",
       " ' and better more intelligence is always better than less intelligence so you',\n",
       " ' So you just...',\n",
       " ' So, you just quicker converge into a state of the art with open source, rather than just',\n",
       " ' building yourself on your own computer.',\n",
       " ' Thank you very much.',\n",
       " ' Yeah',\n",
       " ' Yeah, I had another guy contribute in building the bot thing, that was a TypeScript thing.',\n",
       " ' Yeah, that was a TypeScript thing.',\n",
       " ' on, yeah, that was a TypeScript thing, the bot, I have modified it.',\n",
       " ' I have modified it.',\n",
       " ' I have modified it slightly and I have another people around who are waiting for the product',\n",
       " ' and those guys who worked for me before as my employees building the proprietary product and',\n",
       " ' building the proprietary product and consulting about things and yeah so there is',\n",
       " \" So there is a few people around it, but basically I'm 90% of them.\",\n",
       " ' for now.',\n",
       " ' Yeah',\n",
       " ' Yeah',\n",
       " ' Say it again',\n",
       " ' Say it again',\n",
       " \" Not really, not really, I've been working on VEXA like full-time for the last 18 months and yeah.\",\n",
       " ' And yeah.',\n",
       " \" And, yeah, I've got another project which is outside IT, yeah.\",\n",
       " ' Yeah, we are...',\n",
       " ' Yeah.',\n",
       " ' We are developing international school in Portugal.',\n",
       " \" So, that's the end of this video.\",\n",
       " ' Thank you for watching.',\n",
       " ' Bye!',\n",
       " ' Yeah',\n",
       " ' Yeah',\n",
       " \" Yeah, I have fun in, I, yeah, I've raised a precede round and we, like, we, we, we made\",\n",
       " ' did a half perceived and another half perceived when I decide I really have',\n",
       " \" something to scale. So, I think we'll be soon at the point when there is something to scale,\",\n",
       " ' just because there is actually a business model behind what I am doing.',\n",
       " ' There is a business model, so there is a direct company.',\n",
       " ' there is a business model. So there is a direct competition in the proprietary sector, which is doing really',\n",
       " ' which is doing really fantastically well.',\n",
       " ' Yeah.',\n",
       " \" Yeah, so we'll just yeah, we'll we'll just\",\n",
       " ' Open',\n",
       " ' open source, what they are doing, yeah.',\n",
       " ' Yeah, so',\n",
       " ' I think the, what I should do now is that, actually publish the thing that is in an actual code,',\n",
       " \" so you'll be able to take a look,\",\n",
       " \" and I'm really interested about.\",\n",
       " ' Yeah.',\n",
       " \" Yeah, what's coming next?\",\n",
       " \" Yeah, what's coming next?\",\n",
       " ' Yeah.',\n",
       " ' Yeah.',\n",
       " ' Yeah.',\n",
       " \" Yeah, yeah, just first of all, I'll just share the code so you'd be able to potentially deploy it yourself\",\n",
       " \" but you'll need a GPU for that. But since this thing is running as a docker composing on my...\",\n",
       " \" development computer. I'll just give you an API key so you'll be able to play with the API.\",\n",
       " ' and maybe even like a GPU is not a requirement because you can opt for a',\n",
       " \" a tiny whisper model and that will not be really very helpful but you'll be able to\",\n",
       " \" run it on any device and that's what you basically need in order to get into it.\",\n",
       " \" Thanks for watching, and I'll see you in the next video.\",\n",
       " ' Yeah, I think that that will have a lot of things to discuss on',\n",
       " ' Yeah',\n",
       " ' ones, yeah, we have this called the actual open source, the ones that is, yeah, actual.',\n",
       " ' And I encourage you to join the discord, so you will get there.',\n",
       " ' great',\n",
       " ' great',\n",
       " ' Thank you for listening, it was really, really great to talk to you.',\n",
       " ' Thank you. Good night.',\n",
       " ' Thank you. Good night.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'google_meet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m meeting_id \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m      2\u001b[0m     select([metadata\u001b[38;5;241m.\u001b[39mtables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeetings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mc\u001b[38;5;241m.\u001b[39mid])\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m      3\u001b[0m         and_(\n\u001b[1;32m      4\u001b[0m             metadata\u001b[38;5;241m.\u001b[39mtables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeetings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mc\u001b[38;5;241m.\u001b[39mnative_meeting_id \u001b[38;5;241m==\u001b[39m native_meeting_id,\n\u001b[1;32m      5\u001b[0m             metadata\u001b[38;5;241m.\u001b[39mtables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeetings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mc\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m platform\n\u001b[1;32m      6\u001b[0m         )\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m )\u001b[38;5;241m.\u001b[39mscalar()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m meeting_id:\n\u001b[1;32m     11\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def get_transcript_segments(native_meeting_id, platform):\n",
    "    \n",
    "    \n",
    "    meeting_id = conn.execute(\n",
    "        select([metadata.tables['meetings'].c.id]).where(\n",
    "            and_(\n",
    "                metadata.tables['meetings'].c.native_meeting_id == native_meeting_id,\n",
    "                metadata.tables['meetings'].c.platform == platform\n",
    "            )\n",
    "        )\n",
    "    ).scalar()\n",
    "    \n",
    "    if not meeting_id:\n",
    "        conn.close()\n",
    "        return []\n",
    "    \n",
    "    result = conn.execute(\n",
    "        select([metadata.tables['transcript_segments']]).where(\n",
    "            metadata.tables['transcript_segments'].c.meeting_id == meeting_id\n",
    "        ).order_by(metadata.tables['transcript_segments'].c.start_time)\n",
    "    ).fetchall()\n",
    "    \n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(len(get_transcript_segments(\"nav-yijy-spp\", \"google_meet\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Vexa API Client - Minimal Usage Snippets\"\"\"\n",
    "from vexa_client import VexaClient\n",
    "\n",
    "# --- Client Initialization ---\n",
    "# User client\n",
    "client = VexaClient(\n",
    "    base_url=\"http://localhost:8056\",\n",
    "    api_key=\"your-user-api-key\"\n",
    ")\n",
    "\n",
    "# Admin client \n",
    "admin_client = VexaClient(\n",
    "    base_url=\"http://localhost:8056\",\n",
    "    admin_key=\"supersecretadmintoken\"  # From docker-compose.yml\n",
    ")\n",
    "\n",
    "# --- Admin Operations ---\n",
    "# Create user\n",
    "new_user = admin_client.create_user(email=\"user@example.com\", name=\"New User\")\n",
    "user_id = new_user['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
